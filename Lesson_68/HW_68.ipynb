{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5729a85-3bb1-4249-ba27-4d765ff18924",
   "metadata": {},
   "source": [
    "## 68. Згорткові нейромережі. Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569efca4-be2c-44e7-a204-7964e5b77e0c",
   "metadata": {},
   "source": [
    "### Завдання:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6b303-0645-4b91-800c-c662d210d30c",
   "metadata": {},
   "source": [
    "#### Створіть модель згорткової нейронної мережі (CNN) із трьома шарами. Підключіть Tensorboard, та відобразіть в ньому зміну розподілу ваг моделі, обчислювальний граф моделі та зміну її метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ca9ae-d9ba-4ce4-ac9b-f3e03866b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e3c166-7323-44b6-8a65-aa989cfb6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d6c08-4325-4c98-921a-8db876db3378",
   "metadata": {},
   "source": [
    "Це визначення класу в PyTorch для моделі згорткової нейронної мережі (CNN). Клас успадковує від класу nn.Module, який є базовим класом для всіх модулів нейронних мереж в PyTorch.\n",
    "\n",
    "Метод конструктора класу (init) ініціалізує шари CNN, які включають два згорткові шари (conv1 і conv2), за якими йдуть три повнозв'язні (dense) шари (fc1, fc2 і fc3) та вихідний шар (out). Згорткові шари використовують двовимірну згортку для вивчення просторових особливостей вхідних даних, а повнозв'язні шари використовують лінійні перетворення для створення високорівневих представлень вхідних даних.\n",
    "\n",
    "Метод forward реалізує прохід вперед CNN, який приймає тензор вхідних даних x як аргумент і послідовно застосовує згорткові та повнозв'язні шари для обчислення тензора вихідних даних. Тензор вихідних даних має форму (batch_size, num_classes), де num_classes - кількість вихідних класів для задачі класифікації.\n",
    "\n",
    "Метод forward застосовує функцію активації ReLU до виходу кожного шару, що додає нелінійність до моделі та дозволяє їй вивчати більш складні особливості. Також він використовує максимальне пулінгування, щоб зменшити розмір карт ознак між згортковими шарами, що допомагає зменшити кількість параметрів моделі та запобігти перенавчанню. Нарешті, тензор вихідних даних передається через вихідний шар, який застосовує лінійне перетворення, щоб отримати кінцеві оцінки класифікації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17908bf9-ce5c-4360-a63e-025328a28484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=30)\n",
    "        self.out = nn.Linear(in_features=30, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = torch.flatten(x,start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2329df-1719-4bac-87b9-1e750e1ceca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантажуємо дані \n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"./data\",\n",
    "train = True,\n",
    " download=True,\n",
    "transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size = 100,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e768072-f167-46db-9d34-53657c4a5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Створюємо об'єкт класу SummaryWriter, який дозволяє записувати і відображати результати \n",
    "# візуалізації даних та метрик під час навчання моделі в TensorBoard.\n",
    "tb = SummaryWriter()\n",
    "model = CNN()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bcfd45-6465-4677-abd6-44c79cb183fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 45761 loss: 372.2201583981514\n",
      "epoch: 1 total_correct: 51013 loss: 244.6232704371214\n",
      "epoch: 2 total_correct: 51700 loss: 225.011220946908\n",
      "epoch: 3 total_correct: 52141 loss: 212.66279566287994\n",
      "epoch: 4 total_correct: 52402 loss: 204.64929619431496\n",
      "epoch: 5 total_correct: 52609 loss: 199.54695862531662\n",
      "epoch: 6 total_correct: 52711 loss: 200.36565117537975\n",
      "epoch: 7 total_correct: 52824 loss: 193.8617832660675\n",
      "epoch: 8 total_correct: 52932 loss: 195.5598203241825\n",
      "epoch: 9 total_correct: 53047 loss: 189.591712936759\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True)\n",
    "optimizer = opt.Adam(model.parameters(), lr= 0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images, labels\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "\n",
    "    tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "    tb.add_histogram(\"fc1.bias\", model.fc1.bias, epoch)\n",
    "    tb.add_histogram(\"fc1.weight\", model.fc1.weight, epoch)\n",
    "    tb.add_histogram(\"fc2.bias\", model.fc2.bias, epoch)\n",
    "    tb.add_histogram(\"fc2.weight\", model.fc2.weight, epoch)\n",
    "    tb.add_histogram(\"fc3.bias\", model.fc3.bias, epoch)\n",
    "    tb.add_histogram(\"fc3.weight\", model.fc3.weight, epoch)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68389000-6272-41fe-be04-b2a48d105cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "E0419 17:25:12.580253 4375436736 application.py:125] Failed to load plugin WhatIfToolPluginLoader.load; ignoring it.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard/backend/application.py\", line 123, in TensorBoardWSGIApp\n",
      "    plugin = loader.load(context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard_plugin_wit/wit_plugin_loader.py\", line 57, in load\n",
      "    from tensorboard_plugin_wit.wit_plugin import WhatIfToolPlugin\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard_plugin_wit/wit_plugin.py\", line 40, in <module>\n",
      "    from tensorboard_plugin_wit._utils import common_utils\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard_plugin_wit/_utils/common_utils.py\", line 17, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import classification_pb2\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/classification_pb2.py\", line 15, in <module>\n",
      "    from tensorboard_plugin_wit._vendor.tensorflow_serving.apis import input_pb2 as tensorflow__serving_dot_apis_dot_input__pb2\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/tensorboard_plugin_wit/_vendor/tensorflow_serving/apis/input_pb2.py\", line 37, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/Users/mac/Desktop/Sturtup_Academy/venv/lib/python3.11/site-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
      "    _message.Message._CheckCalledFromGeneratedFile()\n",
      "TypeError: Descriptors cannot not be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.12.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ba7b0-368a-4c49-9691-d99d838cca89",
   "metadata": {},
   "source": [
    "![Alt-текст](1.JPG \"Picture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c845fe1-b53e-4be0-af4f-017adce98bcb",
   "metadata": {},
   "source": [
    "![Alt-текст](2.JPG \"Picture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277a16c7-8fd0-4feb-afab-39f37f915ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.dropbox.com/s/7njrwyk8pgd4swk/1.jpg?dl=0\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://www.dropbox.com/s/7njrwyk8pgd4swk/1.jpg?dl=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fe0467-4f57-4e04-b2ce-ab65e477d0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://drive.google.com/file/d/1LbzSdsW5hJT-mF_VSdWlBJ3B8udbulX9/view?usp=sharing\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://drive.google.com/file/d/1LbzSdsW5hJT-mF_VSdWlBJ3B8udbulX9/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d307180-bd73-4842-9872-e54c551ac6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
